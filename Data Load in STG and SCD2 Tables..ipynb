{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae1c6ec",
   "metadata": {},
   "source": [
    "# File to STG Load\n",
    "\n",
    "We will load latest file data into stage table. Before loading the file, We will truncate the stage table and then load the fresh data. While loading we will also calculate the SHA 256 key for below columns.\n",
    "\n",
    "\t[ID_REVIEW]\n",
    "\t[CAPTION]\n",
    "\t[RELATIVE_DATE]\n",
    "\t[RETRIEVAL_DATE]\n",
    "\t[RATING]\n",
    "\t[USERNAME]\n",
    "\t[N_REVIEW_USER]\n",
    "\t[N_PHOTO_USER]\n",
    "\t[URL_USER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8df3f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table GoogleReviewSTG truncated.\n",
      "Data loaded into GoogleReviewSTG.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration variables\n",
    "file_path = 'D:\\\\MTech\\\\4-SEM\\\\ProjectCode\\\\newest_gm_reviews.csv'  # Update with your file path\n",
    "server = 'LAPTOP-MG2NCG2P\\SQLEXPRESS'       # SQL Server name\n",
    "database = 'GoogleReview'   # Database name\n",
    "username = 'sa'   # DB username\n",
    "password = 'ermifu@AMT606'   # DB password\n",
    "table_name = 'GoogleReviewSTG'  # Stage table name\n",
    "\n",
    "# Create a connection to the SQL Server database\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password}'\n",
    ")\n",
    "\n",
    "# Function to truncate the stage table\n",
    "def truncate_stage_table():\n",
    "    cursor = conn.cursor()\n",
    "    truncate_query = f\"TRUNCATE TABLE {table_name}\"\n",
    "    cursor.execute(truncate_query)\n",
    "    conn.commit()\n",
    "    print(f\"Table {table_name} truncated.\")\n",
    "\n",
    "\n",
    "# Function to truncate the stage table\n",
    "def truncate_stage_table():\n",
    "    cursor = conn.cursor()\n",
    "    truncate_query = f\"TRUNCATE TABLE {table_name}\"\n",
    "    cursor.execute(truncate_query)\n",
    "    conn.commit()\n",
    "    print(f\"Table {table_name} truncated.\")\n",
    "\n",
    "# Function to calculate SHA-256 hash\n",
    "def calculate_sha256(*args):\n",
    "    sha256 = hashlib.sha256()\n",
    "    for arg in args:\n",
    "        sha256.update(str(arg).encode('utf-8') if arg else b'')\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "# Function to convert hex string to binary\n",
    "def hex_to_binary(hex_string):\n",
    "    return bytes.fromhex(hex_string)\n",
    "\n",
    "# Function to load data from the file to the stage table\n",
    "def load_data_to_stage():\n",
    "    # Read the file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Clean column names (strip spaces and lowercase)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    # Define the required columns (matching the actual CSV columns and SQL Server table)\n",
    "    required_columns = ['id_review', 'caption', 'relative_date', 'retrieval_date', \n",
    "                        'rating', 'username', 'n_review_user', 'n_photo_user', 'url_user']\n",
    "\n",
    "    # Check if the cleaned file contains the expected columns\n",
    "    if not set(required_columns).issubset(df.columns):\n",
    "        raise ValueError(f\"The CSV file does not contain the required columns. Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Ensure correct data types for SQL Server table\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce', downcast='integer')  # Smallint in SQL Server\n",
    "    df['n_review_user'] = pd.to_numeric(df['n_review_user'], errors='coerce', downcast='integer')  # Integer in SQL Server\n",
    "\n",
    "    # Get current date and time\n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Generate insert query from DataFrame\n",
    "    cursor = conn.cursor()\n",
    "    for index, row in df.iterrows():\n",
    "        # Calculate SHA-256 hash for each row\n",
    "        sha256_key = calculate_sha256(\n",
    "            row['id_review'], row['caption'], row['relative_date'],\n",
    "            row['retrieval_date'], row['rating'], row['username'],\n",
    "            row['n_review_user'], row['n_photo_user'], row['url_user']\n",
    "        )\n",
    "        sha256_key_binary = hex_to_binary(sha256_key)  # Convert hex string to binary\n",
    "\n",
    "        values = [\n",
    "            \"'{}'\".format(str(row['id_review'])),  # nvarchar(100)\n",
    "            \"'{}'\".format(str(row['caption']).replace(\"'\", \"''\")) if pd.notnull(row['caption']) else 'NULL',  # nvarchar(max)\n",
    "            \"'{}'\".format(str(row['relative_date'])) if pd.notnull(row['relative_date']) else 'NULL',  # nvarchar(100)\n",
    "            \"'{}'\".format(str(row['retrieval_date'])) if pd.notnull(row['retrieval_date']) else 'NULL',  # nvarchar(100)\n",
    "            \"{}\".format(row['rating']) if pd.notnull(row['rating']) else 'NULL',  # smallint\n",
    "            \"'{}'\".format(str(row['username'])) if pd.notnull(row['username']) else 'NULL',  # nvarchar(100)\n",
    "            \"{}\".format(row['n_review_user']) if pd.notnull(row['n_review_user']) else 'NULL',  # int\n",
    "            \"'{}'\".format(str(row['n_photo_user'])) if pd.notnull(row['n_photo_user']) else 'NULL',  # nvarchar(100)\n",
    "            \"'{}'\".format(str(row['url_user'])) if pd.notnull(row['url_user']) else 'NULL',  # nvarchar(100)\n",
    "            \"0x\" + sha256_key_binary.hex(),  # SHA-256 key as binary\n",
    "            \"'ETL_WEB'\",  # CREATE_BY\n",
    "            \"'{}'\".format(current_datetime.strftime('%Y-%m-%d %H:%M:%S')),  # CREATE_DATETIME\n",
    "            \"'{}'\".format(current_datetime.strftime('%Y-%m-%d %H:%M:%S'))  # BUSINESS_DATE\n",
    "        ]\n",
    "        \n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO {} \n",
    "            (id_review, caption, relative_date, retrieval_date, rating, \n",
    "            username, n_review_user, n_photo_user, url_user, SHA_256_KEY, \n",
    "            CREATE_BY, CREATE_DATETIME, BUSINESS_DATE) \n",
    "            VALUES ({})\n",
    "        \"\"\".format(table_name, ', '.join(values))\n",
    "        \n",
    "        cursor.execute(insert_query)\n",
    "\n",
    "    # Commit the transaction to the database\n",
    "    conn.commit()\n",
    "    print(f\"Data loaded into {table_name}.\")\n",
    "\n",
    "# Main function to truncate and load data\n",
    "def main():\n",
    "    truncate_stage_table()  # Truncate the stage table first\n",
    "    load_data_to_stage()    # Load new data from the file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bac7de",
   "metadata": {},
   "source": [
    "# STG To SCD2 Table\n",
    "\n",
    "After loading stage table, we will load the scd2 table. SCD2 table will have historical record with valid from ad valid to date to get latest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601cdc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rohit\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All records successfully inserted into the SCD2 table.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# SQL Server connection details\n",
    "server = 'LAPTOP-MG2NCG2P\\SQLEXPRESS'       # SQL Server name\n",
    "database = 'GoogleReview'   # Database name\n",
    "username = 'sa'   # DB username\n",
    "password = 'ermifu@AMT606'   # DB password\n",
    "\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password}'\n",
    ")\n",
    "\n",
    "connection_string = (\"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "               \"Server=LAPTOP-MG2NCG2P\\SQLEXPRESS;\"\n",
    "               \"Database=GoogleReview;\"\n",
    "               \"UID=sa;\"\n",
    "               \"PWD=ermifu@AMT606;\"\n",
    "               )\n",
    "\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={quote_plus(connection_string)}\")\n",
    "\n",
    "# Connection string for pyodbc\n",
    "\n",
    "# Connect to SQL Server using pyodbc\n",
    "with engine.connect() as connection:\n",
    "    print(\"Connection successful\")\n",
    "\n",
    "# Read data from staging table\n",
    "query_staging = \"SELECT * FROM [DBO].GoogleReviewSTG\"\n",
    "df_staging = pd.read_sql(query_staging, conn)\n",
    "\n",
    "# Check if SCD2 table is empty\n",
    "query_scd2_check = \"SELECT COUNT(*) FROM [dbo].[GoogleReviewSCD2]\"\n",
    "df_scd2_check = pd.read_sql(query_scd2_check, conn)\n",
    "is_scd2_empty = df_scd2_check.iloc[0, 0] == 0\n",
    "\n",
    "# Close connection\n",
    "#conn.close()\n",
    "\n",
    "# If SCD2 table is empty, insert all records from staging\n",
    "if is_scd2_empty:\n",
    "    df_staging['Valid_From'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df_staging['Valid_To'] = '9999-12-31'\n",
    "    \n",
    "    # Connect to SQL Server using SQLAlchemy\n",
    "    #engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "    \n",
    "    # Start a new transaction\n",
    "    with engine.begin() as connection:\n",
    "        # Insert all records into SCD2 table\n",
    "        df_staging.to_sql('GoogleReviewSCD2', connection, if_exists='append', index=False)\n",
    "\n",
    "    print(\"All records successfully inserted into the SCD2 table.\")\n",
    "\n",
    "else:\n",
    "    # Read data from SCD2 table\n",
    "    query_scd2 = \"SELECT * FROM [dbo].[GoogleReviewSCD2] WHERE Valid_To = '9999-12-31'\"\n",
    "    df_scd2 = pd.read_sql(query_scd2, conn)\n",
    "\n",
    "    # Merge staging data with SCD2 data\n",
    "    merged = df_staging.merge(df_scd2, on='ID_REVIEW', suffixes=('_staging', '_scd2'), how='left')\n",
    "\n",
    "    # Identify new records\n",
    "    new_records = merged[merged['SHA_256_KEY_scd2'].isna()]\n",
    "\n",
    "    # Identify changed records\n",
    "    changed_records = merged[~merged['SHA_256_KEY_scd2'].isna() & (merged['SHA_256_KEY_staging'] != merged['SHA_256_KEY_scd2'])]\n",
    "\n",
    "    # Update existing records\n",
    "    update_records = df_scd2[df_scd2['ID_REVIEW'].isin(changed_records['ID_REVIEW'])]\n",
    "\n",
    "    # Set Valid_To for existing records to current date\n",
    "    update_records['Valid_To'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Insert new records\n",
    "    new_records = new_records.drop(columns=[col for col in new_records.columns if col.endswith('_scd2')])\n",
    "    new_records['Valid_From'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_records['Valid_To'] = '9999-12-31'\n",
    "\n",
    "    # Insert changed records\n",
    "    changed_records = changed_records.drop(columns=[col for col in changed_records.columns if col.endswith('_scd2')])\n",
    "    changed_records['Valid_From'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    changed_records['Valid_To'] = '9999-12-31'\n",
    "\n",
    "    # Connect to SQL Server using SQLAlchemy\n",
    "    #\n",
    "    # Start a new transaction\n",
    "    with engine.begin() as connection:\n",
    "        # Update existing records\n",
    "        for _, row in update_records.iterrows():\n",
    "            update_query = f\"\"\"\n",
    "            UPDATE [dbo].[GoogleReviewSCD2]\n",
    "            SET Valid_To = '{row['Valid_To']}'\n",
    "            WHERE ID_REVIEW = '{row['ID_REVIEW']}' AND Valid_To = '9999-12-31'\n",
    "            \"\"\"\n",
    "            connection.execute(update_query)\n",
    "        \n",
    "        # Insert new records\n",
    "        new_records.to_sql('GoogleReviewSCD2', connection, if_exists='append', index=False)\n",
    "        \n",
    "        # Insert changed records\n",
    "        changed_records.to_sql('GoogleReviewSCD2', connection, if_exists='append', index=False)\n",
    "\n",
    "    print(\"Data successfully updated in the SCD2 table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41b5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
